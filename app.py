import streamlit as st
import cv2
import PIL.Image
import numpy as np
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import mediapipe as mp
import tempfile
import os
from datetime import datetime
import io
import zipfile
import math

# ---------------------------------------------------------
# 1. API ÏÑ§Ï†ï
# ---------------------------------------------------------
if "GOOGLE_API_KEY" in st.secrets:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
else:
    # Î°úÏª¨ ÌÖåÏä§Ìä∏Ïö© (Î∞∞Ìè¨ ÏãúÏóêÎäî secretsÍ∞Ä Ïö∞ÏÑ†Îê®)
    GOOGLE_API_KEY = "AIzaSyANlIKJWsIon4JbrR2U-WUosLkfGts8PYs"

try:
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash') 
except Exception as e:
    st.error(f"API ÌÇ§ ÏÑ§Ï†ï Ïò§Î•ò: {e}")

# MediaPipe ÏÑ§Ï†ï
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
RED_STYLE = mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=3, circle_radius=3)
YELLOW_STYLE = mp_drawing.DrawingSpec(color=(0, 255, 255), thickness=3, circle_radius=4)

# ÏïàÏ†Ñ ÏÑ§Ï†ï
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

# ---------------------------------------------------------
# 2. ÏàòÌïôÏ†Å Í≥ÑÏÇ∞ Ìï®Ïàò
# ---------------------------------------------------------
def calculate_angle(a, b, c):
    a = np.array(a)
    b = np.array(b)
    c = np.array(c)
    
    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)
    
    if angle > 180.0:
        angle = 360-angle
        
    return int(angle)

# ---------------------------------------------------------
# 3. ÌïµÏã¨ Î∂ÑÏÑù Ìï®Ïàò
# ---------------------------------------------------------
def extract_frames_from_video_file(video_path, num_frames=10):
    vidcap = cv2.VideoCapture(video_path)
    if not vidcap.isOpened(): return []
    total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))
    if total_frames <= 0: return []
    step = total_frames // (num_frames + 1)
    pil_images = []
    for i in range(1, num_frames + 1):
        vidcap.set(cv2.CAP_PROP_POS_FRAMES, i * step)
        success, image = vidcap.read()
        if success:
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            pil_images.append(PIL.Image.fromarray(image_rgb))
    vidcap.release()
    return pil_images

def analyze_pose_and_draw(pil_image):
    image_np = np.array(pil_image)
    height, width, _ = image_np.shape

    with mp_pose.Pose(static_image_mode=True, model_complexity=2, enable_segmentation=False, min_detection_confidence=0.5) as pose:
        results = pose.process(image_np)
        annotated_image = image_np.copy()
        
        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            
            mp_drawing.draw_landmarks(
                annotated_image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                landmark_drawing_spec=RED_STYLE, connection_drawing_spec=RED_STYLE
            )

            # Í∞ÅÎèÑ Í≥ÑÏÇ∞ Î°úÏßÅ
            hip_l = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x * width, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y * height]
            knee_l = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x * width, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y * height]
            ankle_l = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x * width, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y * height]
            
            hip_r = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x * width, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y * height]
            knee_r = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x * width, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y * height]
            ankle_r = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x * width, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y * height]

            angle_l = calculate_angle(hip_l, knee_l, ankle_l)
            angle_r = calculate_angle(hip_r, knee_r, ankle_r)

            cv2.putText(annotated_image, f"{angle_l}", tuple(np.multiply(knee_l, [1, 1]).astype(int)), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3, cv2.LINE_AA)
            cv2.putText(annotated_image, f"{angle_r}", tuple(np.multiply(knee_r, [1, 1]).astype(int)), 
                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 3, cv2.LINE_AA)

            # ÌõÑÍ≤Ω Ï≤¥ÌÅ¨
            mid_hip_x = (hip_l[0] + hip_r[0]) / 2
            mid_ankle_x = (ankle_l[0] + ankle_r[0]) / 2
            
            cv2.line(annotated_image, (int(mid_hip_x), int(hip_l[1])), (int(mid_hip_x), int(ankle_l[1])), (255, 255, 0), 2)
            
            if angle_l > 165 or angle_r > 165:
                 cv2.putText(annotated_image, "HIGH!", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 4, cv2.LINE_AA)

    return PIL.Image.fromarray(annotated_image)

def generate_feedback_with_captions(frames, student_name, coach_name, weekly_goal, morning_note, afternoon_note):
    today_date = datetime.now().strftime("%m/%d")
    frame_count = len(frames)
    
    if not morning_note: morning_note = "Í∏∞Ï¥à ÌõàÎ†® ÏßÑÌñâ"
    if not afternoon_note: afternoon_note = "Ïã¨Ìôî ÌõàÎ†® ÏßÑÌñâ"

    prompt = f"""
    ÎãπÏã†ÏùÄ Ïä§ÌÇ§ ÌåÄÏùò Îã¥Îãπ ÏΩîÏπò '{coach_name}'ÏûÖÎãàÎã§.
    Ï†úÍ≥µÎêú {frame_count}Ïû•Ïùò ÏÇ¨ÏßÑÏùÄ ÏàòÍ∞ïÏÉù '{student_name}'ÎãòÏùò Ïä§ÌÇ§ ÌÉÄÎäî Î™®ÏäµÏûÖÎãàÎã§.
    ÏÇ¨ÏßÑÏóêÎäî **Î¨¥Î¶é Í∞ÅÎèÑ(Ïà´Ïûê)**ÏôÄ **ÏûêÏÑ∏ ÎºàÎåÄ**Í∞Ä Í∑∏Î†§Ï†∏ ÏûàÏäµÎãàÎã§. Ïù¥ Îç∞Ïù¥ÌÑ∞Î•º Ï∞∏Í≥†ÌïòÏó¨ Î∂ÑÏÑùÌï¥ Ï£ºÏÑ∏Ïöî.
    
    [ÌïµÏã¨ ÏßÄÏãúÏÇ¨Ìï≠]
    ÏïÑÎûò 'ÏΩîÏπòÍ∞Ä ÏûÖÎ†•Ìïú ÌõàÎ†® ÎÇ¥Ïö©'ÏùÑ Î∞îÌÉïÏúºÎ°ú ÌîºÎìúÎ∞±ÏùÑ ÏûëÏÑ±Ìï¥ Ï£ºÏÑ∏Ïöî.
    ÏûÖÎ†• ÎÇ¥Ïö©ÏùÑ ÏµúÎåÄÌïú Î∞òÏòÅÌïòÎêò, Î¨∏Ïû•ÏùÑ ÏµúÏã† Ïä§ÌÇ§ Ïö©Ïñ¥ÏôÄ Ï†ÑÎ¨∏Ï†ÅÏù∏ 'Ìï¥ÏöîÏ≤¥'Î°ú Îã§Îì¨Ïñ¥ Ï£ºÏÑ∏Ïöî.
    
    [ÏûÖÎ†• Ï†ïÎ≥¥]
    - ÌöåÏõê: {student_name}
    - ÏùºÏûê: {today_date}
    - Îã¥Îãπ: {coach_name} ÏΩîÏπò
    - Ï£ºÍ∞Ñ Î™©Ìëú: {weekly_goal}
    
    [ÏΩîÏπòÍ∞Ä ÏûÖÎ†•Ìïú ÌõàÎ†® ÎÇ¥Ïö©]
    - Ïò§Ï†Ñ Ìè¨Ïù∏Ìä∏: {morning_note}
    - Ïò§ÌõÑ Ìè¨Ïù∏Ìä∏: {afternoon_note}

    [Ï∂úÎ†• ÏñëÏãù]
    Îëê Í∞ÄÏßÄ ÌååÌä∏Î°ú ÎÇòÎàÑÍ≥†, ÏÇ¨Ïù¥ÏóêÎäî '|||' (ÌååÏù¥ÌîÑ 3Í∞ú)Î•º ÎÑ£Ïñ¥Ï£ºÏÑ∏Ïöî.

    [PART 1: ÌïôÎ∂ÄÎ™® Ï†ÑÏÜ°Ïö© ÌîºÎìúÎ∞±]
    {student_name} - ‚õ∑ ÎπÑÎ∞î365 Î†àÏä® ÌîºÎìúÎ∞±

    ‚ú™ ÏΩîÎìú : S ÌÅ¥ÎûòÏä§
    ‚ú™ ÌöåÏõê : {student_name}
    ‚ú™ ÏùºÏûê : {today_date}
    ‚ú™ Îã¥Îãπ : {coach_name} ÏΩîÏπò

    ‚àé Ï£ºÍ∞Ñ ÍµêÏú°Í≥ºÏ†ï Î∞è Î™©Ìëú
    {weekly_goal}

    üìåÏò§Ï†Ñ : 
    (Ïò§Ï†Ñ Ìè¨Ïù∏Ìä∏ ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú 3Ï§Ñ ÏûëÏÑ±)

    üìå Ïò§ÌõÑ ÍµêÏú° : 
    (Ïò§ÌõÑ Ìè¨Ïù∏Ìä∏ ÎÇ¥Ïö©ÏùÑ Î∞îÌÉïÏúºÎ°ú 3Ï§Ñ ÏûëÏÑ±)

    (Ïπ≠Ï∞¨ Î©òÌä∏)

    ÏãúÏ¶åÎ∞ò SÌÅ¥ÎûòÏä§Ïùò ÌîºÎìúÎ∞±ÏùÄ Îß§Ïùº Ï†ÑÎã¨ÎêòÎäî Î∞©ÏãùÏù¥ ÏïÑÎãàÎùº,
    ÏïÑÏù¥Îì§Ïùò Î∞úÏ†Ñ Îã®Í≥ÑÏôÄ ÌïÑÏöîÏóê Îî∞Îùº ÏàòÏãúÎ°ú Ï†úÍ≥µÎêòÍ≥† ÏûàÏäµÎãàÎã§.
    
    Ï°∞Í∏àÎßå ÎØøÍ≥† ÏßÄÏºúÎ¥ê Ï£ºÏãúÎ©¥, Îçî ÌÅ∞ ÏÑ±Ïû•Ïùò Í∞êÎèôÏùÑ Ï†ÑÎã¨ ÎìúÎ¶¨Í≤†ÏäµÎãàÎã§.üòä

    
    [PART 2: ÏÇ¨ÏßÑÎ≥Ñ Î∂ÑÏÑù]
    Í∞Å ÏÇ¨ÏßÑ(1Î≤à~{frame_count}Î≤à)Ïóê ÎåÄÌï¥ 'Ï≤¥ÌÅ¨ Ìè¨Ïù∏Ìä∏'Î•º Ìïú Î¨∏Ïû•ÏúºÎ°ú ÏûëÏÑ±.
    Íµ¨Î∂ÑÏûêÎäî '###' ÏÇ¨Ïö©.
    """
    
    response = model.generate_content([prompt, *frames], safety_settings=safety_settings)
    if response.parts: return response.text
    else: return "Î∂ÑÏÑù Ïã§Ìå® ||| Î∂ÑÏÑù Ïã§Ìå® ### Î∂ÑÏÑù Ïã§Ìå®"

def create_zip_file(images, selected_indices):
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zf:
        for idx in selected_indices:
            img = images[idx]
            img_byte_arr = io.BytesIO()
            img.save(img_byte_arr, format='JPEG', quality=95)
            zf.writestr(f"ski_scene_{idx+1}.jpg", img_byte_arr.getvalue())
    return zip_buffer.getvalue()

# ---------------------------------------------------------
# 4. Î©îÏù∏ Ïõπ ÌôîÎ©¥
# ---------------------------------------------------------
st.set_page_config(page_title="AI Ïä§ÌÇ§ ÏΩîÏπò Pro", page_icon="‚õ∑Ô∏è")
st.title("‚õ∑Ô∏è Ïä§ÌÇ§ Ï†ïÎ∞Ä Î∂ÑÏÑùÍ∏∞ (Pro Ver.)")
st.caption("AI Vision + ÏàòÌïôÏ†Å Í∞ÅÎèÑ Í≥ÑÏÇ∞Ïù¥ Ìè¨Ìï®Îêú Î≤ÑÏ†ÑÏûÖÎãàÎã§.")

if 'analyzed_images' not in st.session_state:
    st.session_state.analyzed_images = []
if 'captions' not in st.session_state:
    st.session_state.captions = []
if 'main_feedback' not in st.session_state:
    st.session_state.main_feedback = ""

with st.form("feedback_form"):
    uploaded_file = st.file_uploader("ÎèôÏòÅÏÉÅ ÏóÖÎ°úÎìú", type=['mp4', 'mov'])
    col1, col2 = st.columns(2)
    with col1: student_name = st.text_input("ÌöåÏõê Ïù¥Î¶Ñ", placeholder="ÍπÄÏäπÌõÑ")
    with col2: coach_name = st.text_input("Îã¥Îãπ ÏΩîÏπò", placeholder="Ïã†Ï†ïÏö∞")
    weekly_goal = st.text_input("Ï£ºÍ∞Ñ ÍµêÏú° Î™©Ìëú", placeholder="Ìå®Îü¨Î†ê ÌÑ¥")
    
    col_am, col_pm = st.columns(2)
    with col_am: morning_note = st.text_area("üìå Ïò§Ï†Ñ ÍµêÏú° ÎÇ¥Ïö©", height=80)
    with col_pm: afternoon_note = st.text_area("üìå Ïò§ÌõÑ ÍµêÏú° ÎÇ¥Ïö©", height=80)
    
    submitted = st.form_submit_button("üöÄ Ï†ïÎ∞Ä Î∂ÑÏÑù ÏãúÏûë")

if submitted:
    if not uploaded_file:
        st.warning("ÏòÅÏÉÅÏùÑ Î®ºÏ†Ä ÏóÖÎ°úÎìúÌï¥Ï£ºÏÑ∏Ïöî.")
    elif GOOGLE_API_KEY == "Ïó¨Í∏∞Ïóê_Î∞úÍ∏âÎ∞õÏùÄ_API_ÌÇ§Î•º_ÎÑ£ÏúºÏÑ∏Ïöî":
        st.error("API ÌÇ§ ÌôïÏù∏ ÌïÑÏöî")
    else:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        tfile.write(uploaded_file.read())
        tfile.close()
        video_path = tfile.name

        try:
            with st.spinner("1Îã®Í≥Ñ: Í¥ÄÏ†à Í∞ÅÎèÑ Í≥ÑÏÇ∞ Î∞è ÏãúÍ∞ÅÌôî Ï§ë..."):
                raw_frames = extract_frames_from_video_file(video_path, num_frames=10)
                processed_frames = []
                for frame in raw_frames:
                    processed_frames.append(analyze_pose_and_draw(frame))
                st.session_state.analyzed_images = processed_frames

            if raw_frames:
                with st.spinner("2Îã®Í≥Ñ: Îç∞Ïù¥ÌÑ∞ Í∏∞Î∞ò AI Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ± Ï§ë..."):
                    full_response = generate_feedback_with_captions(
                        raw_frames, student_name, coach_name, weekly_goal, morning_note, afternoon_note
                    )
                    try:
                        parts = full_response.split("|||")
                        st.session_state.main_feedback = parts[0].strip()
                        if len(parts) > 1: st.session_state.captions = parts[1].strip().split("###")
                        else: st.session_state.captions = ["Î∂ÑÏÑù ÎÇ¥Ïö© ÏóÜÏùå"] * len(raw_frames)
                    except:
                        st.session_state.main_feedback = full_response
                        st.session_state.captions = ["Ïò§Î•ò"] * len(raw_frames)
            else:
                st.error("ÏòÅÏÉÅ Ï≤òÎ¶¨ Ïã§Ìå®")
        except Exception as e:
            st.error(f"Ïò§Î•ò: {e}")
        finally:
            if os.path.exists(video_path): os.unlink(video_path)

if st.session_state.analyzed_images:
    st.divider()
    st.subheader(f"üì∏ Ï†ïÎ∞Ä Î∂ÑÏÑù Í≤∞Í≥º (Ï¥ù {len(st.session_state.analyzed_images)}Ïû•)")
    st.info("Î¨¥Î¶é ÏòÜÏùò ÎÖ∏ÎûÄÏÉâ Ïà´ÏûêÎäî 'Í¥ÄÏ†àÏùò Í∞ÅÎèÑ'ÏûÖÎãàÎã§.")

    selected_indices = []
    # -------------------------------------------------------------
    # [ÏàòÏ†ïÎê®] use_container_width=True -> width="stretch" Î°ú Î≥ÄÍ≤Ω
    # -------------------------------------------------------------
    for i in range(0, len(st.session_state.analyzed_images), 2):
        cols = st.columns(2)
        with cols[0]:
            if i < len(st.session_state.analyzed_images):
                st.image(st.session_state.analyzed_images[i], width="stretch")
                caption = st.session_state.captions[i].strip() if i < len(st.session_state.captions) else ""
                st.info(f"{i+1}. {caption}")
                if st.checkbox(f"ÏÑ†ÌÉù {i+1}", key=f"c{i}"): selected_indices.append(i)
        with cols[1]:
            if i+1 < len(st.session_state.analyzed_images):
                st.image(st.session_state.analyzed_images[i+1], width="stretch")
                caption = st.session_state.captions[i+1].strip() if i+1 < len(st.session_state.captions) else ""
                st.info(f"{i+2}. {caption}")
                if st.checkbox(f"ÏÑ†ÌÉù {i+2}", key=f"c{i+1}"): selected_indices.append(i+1)

    st.markdown("---")
    if selected_indices:
        zip_data = create_zip_file(st.session_state.analyzed_images, selected_indices)
        st.download_button("üì¶ ÏÑ†ÌÉùÌïú ÏÇ¨ÏßÑ Îã§Ïö¥Î°úÎìú (ZIP)", data=zip_data, file_name=f"{student_name}_analysis.zip", mime="application/zip", type="primary")

    st.divider()
    st.subheader("üìù ÌîºÎìúÎ∞± Î¶¨Ìè¨Ìä∏")
    st.text_area("Ïπ¥ÌÜ° Ï†ÑÏÜ°Ïö©", st.session_state.main_feedback, height=350)